{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "653089c9",
   "metadata": {},
   "source": [
    "# Chapter 13: Deep Learning in Connect Four\n",
    "\n",
    "New Skills in This Chapter\n",
    "\n",
    "• Creating a Connect Four game environment\n",
    "\n",
    "• Coding in complicated Connect Four game rules\n",
    "\n",
    "• Simulating game data to train a deep neural network\n",
    "\n",
    "• Designing deep learning game strategies for different players"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b25bf6",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "***\n",
    "*Predicting better than pure guesswork, even if not accurately, delivers real value. A\n",
    "hazy view of what’s to come outperforms complete darkness by a landslide.*\n",
    "\n",
    "\n",
    "–Eric Seigel, Predictive Analytics: The Power to Predict Who Will Click, Buy, Lie, or Die\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "117477d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"files/ch13\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282ad876",
   "metadata": {},
   "source": [
    "# 13.1. Create A Connect Four Game Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee28a4e",
   "metadata": {},
   "source": [
    "## 13.1.2. Verify the Connect Four Game Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a847d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.conn_env import conn\n",
    "\n",
    "env = conn()\n",
    "env.reset()                    \n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e6bd0a",
   "metadata": {},
   "source": [
    "You should see a separate turtle window, with a game board as follows: \n",
    "<img src=\"https://gattonweb.uky.edu/faculty/lium/ml/conn_start.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0977029b",
   "metadata": {},
   "source": [
    "If you want to close the game board window, use the *close()* method, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "439f093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15b9c0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of possible actions is 7\n",
      "the shape of the observation space is (7, 6)\n"
     ]
    }
   ],
   "source": [
    "env=conn()\n",
    "# check the action space\n",
    "number_actions = env.action_space.n\n",
    "print(\"the number of possible actions is\", number_actions)\n",
    "# check the shape of the observation space\n",
    "print(\"the shape of the observation space is\",\\\n",
    "      env.observation_space.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2033eed1",
   "metadata": {},
   "source": [
    "The meanings of the actions in this game are as follows\n",
    "* 1: Placing a game piece in column 1\n",
    "* 2: Placing a game piece in column 2\n",
    "* ...\n",
    "* 7: Placing a game piece in column 7\n",
    "\n",
    "\n",
    "The state space is a matrix with 7 columns and 6 rows: \n",
    "* 0 means the cell is empty; \n",
    "* -1 means the cell is occupied by the yellow player; \n",
    "* 1 means the cell is occupied by the red player."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064889bb",
   "metadata": {},
   "source": [
    "## 13.1.3. Play A Connect Four Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aac17214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the current state is \n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "enter a number between 1 and 7\n",
      "Player red, what's your move?4\n",
      "Player red has chosen action 4\n",
      "the current state is \n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]]\n",
      "Player yellow has chosen action 6\n",
      "the current state is \n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0 -1  0]]\n",
      "Player red, what's your move?3\n",
      "Player red has chosen action 3\n",
      "the current state is \n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  1  1  0 -1  0]]\n",
      "Player yellow has chosen action 4\n",
      "the current state is \n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0 -1  0  0  0]\n",
      " [ 0  0  1  1  0 -1  0]]\n",
      "Player red, what's your move?2\n",
      "Player red has chosen action 2\n",
      "the current state is \n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0 -1  0  0  0]\n",
      " [ 0  1  1  1  0 -1  0]]\n",
      "Player yellow has chosen action 5\n",
      "the current state is \n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0 -1  0  0  0]\n",
      " [ 0  1  1  1 -1 -1  0]]\n",
      "Player red, what's your move?1\n",
      "Player red has chosen action 1\n",
      "the current state is \n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0 -1  0  0  0]\n",
      " [ 1  1  1  1 -1 -1  0]]\n",
      "Player red has won!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "env=conn()\n",
    "state=env.reset()   \n",
    "env.render()\n",
    "print(f\"the current state is \\n{state.T[::-1]}\")    \n",
    "print('enter a number between 1 and 7')\n",
    "while True:   \n",
    "    action=int(input(\"Player red, what's your move?\"))\n",
    "    time.sleep(1)\n",
    "    print(f\"Player red has chosen action {action}\")    \n",
    "    state,reward,done,info=env.step(action)\n",
    "    print(f\"the current state is \\n{state.T[::-1]}\")\n",
    "    env.render()\n",
    "    if done:\n",
    "        if reward==1:\n",
    "            print(f\"Player red has won!\") \n",
    "        else:\n",
    "            print(f\"It's a tie!\") \n",
    "        break\n",
    "    action=random.choice(env.validinputs)\n",
    "    time.sleep(1)\n",
    "    print(f\"Player yellow has chosen action {action}\")    \n",
    "    state,reward,done,info=env.step(action)\n",
    "    env.render()\n",
    "    print(f\"the current state is \\n{state.T[::-1]}\")\n",
    "    if done:\n",
    "        if reward==-1:\n",
    "            print(f\"Player yellow has won!\") \n",
    "        else:\n",
    "            print(f\"It's a tie!\") \n",
    "        break    \n",
    "env.close()      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcbdf00",
   "metadata": {},
   "source": [
    "# 13.2. Train A Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c150fb",
   "metadata": {},
   "source": [
    "## 13.2.2. Simulate Connect Four Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b436040",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0]]),\n",
      " array([[ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 1,  0,  0,  0,  0,  0]]),\n",
      " array([[ 1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 1,  0,  0,  0,  0,  0]]),\n",
      " array([[ 1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 1, -1,  0,  0,  0,  0]]),\n",
      " array([[ 1,  1,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 1, -1,  0,  0,  0,  0]]),\n",
      " array([[ 1,  1,  0,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 1, -1,  0,  0,  0,  0]]),\n",
      " array([[ 1,  1,  1,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 1, -1,  0,  0,  0,  0]]),\n",
      " array([[ 1,  1,  1, -1,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 1, -1,  0,  0,  0,  0]]),\n",
      " array([[ 1,  1,  1, -1,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  1,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 1, -1,  0,  0,  0,  0]]),\n",
      " array([[ 1,  1,  1, -1,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  1, -1,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 1, -1,  0,  0,  0,  0]]),\n",
      " array([[ 1,  1,  1, -1,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  1, -1,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 1, -1,  1,  0,  0,  0]]),\n",
      " array([[ 1,  1,  1, -1,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  1, -1,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 1, -1,  1,  0,  0,  0]]),\n",
      " array([[ 1,  1,  1, -1,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  1, -1,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 1, -1,  1,  1,  0,  0]]),\n",
      " array([[ 1,  1,  1, -1, -1,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  1, -1,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 1, -1,  1,  1,  0,  0]]),\n",
      " array([[ 1,  1,  1, -1, -1,  1],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  1, -1,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 1, -1,  1,  1,  0,  0]]),\n",
      " array([[ 1,  1,  1, -1, -1,  1],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  1, -1,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 1, -1,  1,  1, -1,  0]]),\n",
      " array([[ 1,  1,  1, -1, -1,  1],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  1, -1,  1,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 1, -1,  1,  1, -1,  0]]),\n",
      " array([[ 1,  1,  1, -1, -1,  1],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  1, -1,  1, -1,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 1, -1,  1,  1, -1,  0]]),\n",
      " array([[ 1,  1,  1, -1, -1,  1],\n",
      "       [-1,  1,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  1, -1,  1, -1,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 1, -1,  1,  1, -1,  0]]),\n",
      " array([[ 1,  1,  1, -1, -1,  1],\n",
      "       [-1,  1,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  1, -1,  1, -1,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 1, -1,  1,  1, -1,  0]]),\n",
      " array([[ 1,  1,  1, -1, -1,  1],\n",
      "       [-1,  1,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  1, -1,  1, -1,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [-1,  1,  0,  0,  0,  0],\n",
      "       [ 1, -1,  1,  1, -1,  0]]),\n",
      " array([[ 1,  1,  1, -1, -1,  1],\n",
      "       [-1,  1,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  1, -1,  1, -1, -1],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [-1,  1,  0,  0,  0,  0],\n",
      "       [ 1, -1,  1,  1, -1,  0]]),\n",
      " array([[ 1,  1,  1, -1, -1,  1],\n",
      "       [-1,  1,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  1, -1,  1, -1, -1],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [-1,  1,  0,  0,  0,  0],\n",
      "       [ 1, -1,  1,  1, -1,  1]]),\n",
      " array([[ 1,  1,  1, -1, -1,  1],\n",
      "       [-1,  1, -1,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  1, -1,  1, -1, -1],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [-1,  1,  0,  0,  0,  0],\n",
      "       [ 1, -1,  1,  1, -1,  1]]),\n",
      " array([[ 1,  1,  1, -1, -1,  1],\n",
      "       [-1,  1, -1,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  1, -1,  1, -1, -1],\n",
      "       [-1,  1,  0,  0,  0,  0],\n",
      "       [-1,  1,  0,  0,  0,  0],\n",
      "       [ 1, -1,  1,  1, -1,  1]]),\n",
      " array([[ 1,  1,  1, -1, -1,  1],\n",
      "       [-1,  1, -1,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [-1,  1, -1,  1, -1, -1],\n",
      "       [-1,  1,  0,  0,  0,  0],\n",
      "       [-1,  1,  0,  0,  0,  0],\n",
      "       [ 1, -1,  1,  1, -1,  1]])]\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "env=conn()\n",
    "def one_game():\n",
    "    history=[]\n",
    "    state=env.reset()   \n",
    "    while True:   \n",
    "        action=random.choice(env.validinputs)  \n",
    "        state,reward,done,info=env.step(action)\n",
    "        history.append(np.array(state).reshape(7,6))\n",
    "        if done:\n",
    "            break\n",
    "    return history, reward\n",
    "# Simulate one game and print out results\n",
    "history,outcome=one_game()\n",
    "pprint(history)\n",
    "pprint(outcome)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c123bb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate 100000 games\n",
    "results=[]        \n",
    "for x in range(100000):\n",
    "    history,outcome=one_game()\n",
    "    # Associate each board with the game outcome\n",
    "    for board in history:\n",
    "        results.append((outcome,board))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3e9e193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-1,\n",
      "  array([[1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0]])),\n",
      " (-1,\n",
      "  array([[ 1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0]])),\n",
      " (-1,\n",
      "  array([[ 1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 1,  0,  0,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0]])),\n",
      " (-1,\n",
      "  array([[ 1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 1,  0,  0,  0,  0,  0],\n",
      "       [-1, -1,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0]])),\n",
      " (-1,\n",
      "  array([[ 1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 1,  0,  0,  0,  0,  0],\n",
      "       [-1, -1,  0,  0,  0,  0],\n",
      "       [ 1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0]])),\n",
      " (-1,\n",
      "  array([[ 1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 1,  0,  0,  0,  0,  0],\n",
      "       [-1, -1, -1,  0,  0,  0],\n",
      "       [ 1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0]])),\n",
      " (-1,\n",
      "  array([[ 1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 1,  0,  0,  0,  0,  0],\n",
      "       [-1, -1, -1,  0,  0,  0],\n",
      "       [ 1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 1,  0,  0,  0,  0,  0]])),\n",
      " (-1,\n",
      "  array([[ 1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 1,  0,  0,  0,  0,  0],\n",
      "       [-1, -1, -1, -1,  0,  0],\n",
      "       [ 1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 1,  0,  0,  0,  0,  0]])),\n",
      " (1,\n",
      "  array([[0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0]])),\n",
      " (1,\n",
      "  array([[ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0],\n",
      "       [-1,  0,  0,  0,  0,  0],\n",
      "       [ 0,  0,  0,  0,  0,  0]]))]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# save the simulation data on your computer\n",
    "with open('files/ch13/games_conn100K.p', 'wb') as fp:\n",
    "    pickle.dump(results,fp)\n",
    "# read the data and print out the first 10 observations       \n",
    "with open('files/ch13/games_conn100K.p', 'rb') as fp:\n",
    "    games=pickle.load(fp)\n",
    "pprint(games[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26a0ec8",
   "metadata": {},
   "source": [
    "## 13.2.3. Train the Connect Four Game Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8951821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv2D(filters=128,kernel_size=(4, 4),padding=\"same\", \n",
    "                 activation=\"relu\", input_shape=(7,6,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=64, activation=\"relu\"))\n",
    "model.add(Dense(units=64, activation=\"relu\"))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                   optimizer='adam', \n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "508c5979",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('files/ch13/games_conn100K.p', 'rb') as fp:\n",
    "    games=pickle.load(fp)\n",
    "\n",
    "boards = []\n",
    "outcomes = []\n",
    "for game in games:\n",
    "    boards.append(game[1])\n",
    "    outcomes.append(game[0])\n",
    "\n",
    "X = np.array(boards).reshape((-1, 7, 6, 1))\n",
    "# one_hot encoder, three outcomes: -1, 0, and 1\n",
    "y = to_categorical(outcomes, num_classes=3)\n",
    "\n",
    "# Train the model for 100 epochs\n",
    "model.fit(X, y, epochs=100, verbose=1)\n",
    "model.save('files/ch13/trained_conn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14805aac",
   "metadata": {},
   "source": [
    "# 13.3. Use the Trained Model to Play Connect Four"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b277b0",
   "metadata": {},
   "source": [
    "## 13.3.1. Best Moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2efd4a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_move_red(env):\n",
    "    # if there is only one valid move, take it\n",
    "    if len(env.validinputs)==1:\n",
    "        return env.validinputs[0]\n",
    "    # set the initial value of bestoutcome        \n",
    "    bestoutcome=-2;\n",
    "    bestmove=None    \n",
    "    # go through all possible moves hypothetically \n",
    "    for move in env.validinputs:\n",
    "        env_copy=deepcopy(env)\n",
    "        state,reward,done,info=env_copy.step(move)\n",
    "        state=state.reshape(-1,7,6,1)\n",
    "        prediction=reload.predict(state,verbose=0)\n",
    "        # Prob of red wins\n",
    "        p_win_red=prediction[0][1]\n",
    "        if p_win_red>bestoutcome:\n",
    "            # Update the bestoutcome\n",
    "            bestoutcome=p_win_red\n",
    "            # Update the best move\n",
    "            bestmove=move\n",
    "    return bestmove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c142967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_move_yellow(env):\n",
    "    # if there is only one valid move, take it\n",
    "    if len(env.validinputs)==1:\n",
    "        return env.validinputs[0]\n",
    "    # set the initial value of bestoutcome        \n",
    "    bestoutcome=-2;\n",
    "    bestmove=None    \n",
    "    # go through all possible moves hypothetically \n",
    "    for move in env.validinputs:\n",
    "        env_copy=deepcopy(env)\n",
    "        state,reward,done,info=env_copy.step(move)\n",
    "        state=state.reshape(-1,7,6,1)\n",
    "        prediction=reload.predict(state,verbose=0)\n",
    "        # Prob of yellow wins\n",
    "        p_win_yellow=prediction[0][2]\n",
    "        if p_win_yellow>bestoutcome:\n",
    "            # Update the bestoutcome\n",
    "            bestoutcome=p_win_yellow\n",
    "            # Update the best move\n",
    "            bestmove=move\n",
    "    return bestmove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525e5801",
   "metadata": {},
   "source": [
    "## 13.3.2. Test Connect Four Deep Learning Game Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d392cd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "reload=load_model('files/ch13/trained_conn.h5')\n",
    "\n",
    "env=conn()\n",
    "results=[]\n",
    "for i in range(100):\n",
    "    state=env.reset() \n",
    "    if i%2==0:\n",
    "        action=random.choice(env.validinputs)\n",
    "        state, reward, done, info=env.step(action)\n",
    "    while True:\n",
    "        if env.turn==\"red\":\n",
    "            action=best_move_red(env) \n",
    "        else:\n",
    "            action=best_move_yellow(env)    \n",
    "        state, reward, done, info=env.step(action)\n",
    "        if done:\n",
    "            # result is 1 if the deep learning agent wins\n",
    "            if reward!=0:\n",
    "                results.append(1) \n",
    "            else:\n",
    "                results.append(0)    \n",
    "            break  \n",
    "        action=random.choice(env.validinputs)   \n",
    "        state, reward, done, info=env.step(action)\n",
    "        if done:\n",
    "            # result is -1 if the deep learning agent loses\n",
    "            if reward!=0:\n",
    "                results.append(-1) \n",
    "            else:\n",
    "                results.append(0)    \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f806366f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the deep learning agent has won 100 games\n",
      "the deep learning agent has lost 0 games\n",
      "the game has tied 0 times\n"
     ]
    }
   ],
   "source": [
    "# count how many times the MCTS agent won\n",
    "wins=results.count(1)\n",
    "print(f\"the deep learning agent has won {wins} games\")\n",
    "# count how many times the MCTS agent lost\n",
    "losses=results.count(-1)\n",
    "print(f\"the deep learning agent has lost {losses} games\")         \n",
    "# count how many times the game ties\n",
    "losses=results.count(0)\n",
    "print(f\"the game has tied {losses} times\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a3674b",
   "metadata": {},
   "source": [
    "# 13.4. Animate Deep Learning in Connect Four"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d2dd43",
   "metadata": {},
   "source": [
    "## 13.4.1. Print Out Probabilities of Winning for Each Next Move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5673933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ch13util import record_conn\n",
    "\n",
    "history=record_conn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "431d5f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the red player chooses action 1, the probability of winning is 0.3281.\n",
      "If the red player chooses action 2, the probability of winning is 0.3718.\n",
      "If the red player chooses action 3, the probability of winning is 0.4599.\n",
      "If the red player chooses action 4, the probability of winning is 0.4793.\n",
      "If the red player chooses action 5, the probability of winning is 0.4599.\n",
      "If the red player chooses action 6, the probability of winning is 0.4495.\n",
      "If the red player chooses action 7, the probability of winning is 0.4096.\n"
     ]
    }
   ],
   "source": [
    "p_wins_step0=history[0][1]\n",
    "for key, value in p_wins_step0.items():\n",
    "    print(f\"If red chooses {key},\\\n",
    " the probability of winning is {value:.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c51cbf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the game history on your computer\n",
    "with open('files/ch13/conn_game_history.p','wb') as fp:\n",
    "    pickle.dump(history,fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507a0fe6",
   "metadata": {},
   "source": [
    "## 13.4.2. Animate A Complete Connect Four Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4deaf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from PIL import Image\n",
    "\n",
    "frames=[]\n",
    "for i in range(8):\n",
    "    im=Image.open(f\"files/ch13/conn_step{i}.ps\")\n",
    "    frame=np.asarray(im)\n",
    "    frames.append(frame) \n",
    "imageio.mimsave(\"files/ch13/conn_steps.gif\",\\\n",
    "                frames,duration=1000)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea21ada",
   "metadata": {},
   "source": [
    "If you open the file conn_steps.gif, you'll see the following: \n",
    "<img src=\"https://gattonweb.uky.edu/faculty/lium/ml/conn_steps.gif\"/>\n",
    "\n",
    "The animation shows the game board at each stage of the game. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72e9512",
   "metadata": {},
   "source": [
    "## 13.4.3. Animate the Decision-Making Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "477c12fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ch13util import stage_pics\n",
    "\n",
    "stage_pics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a728554",
   "metadata": {},
   "source": [
    "The above script highlights the decision making process of the red player. For example, if you open the file conn_stage0step3.png, you'll see the following picture.\n",
    "<img src=\"https://gattonweb.uky.edu/faculty/lium/ml/conn_stage0step3.png\" /> It shows the probabilities of the red player winning the game with each hypothetical move. In particular, the probability is 47.93% if the red player chooses Column 4. The choice is highlighted in blue, and that is also the move made by the red player as a result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd048656",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[]\n",
    "\n",
    "for stage in range(len(history)):\n",
    "    for step in [1,2,3]:\n",
    "        file=f\"conn_stage{stage*2}step{step}.png\"\n",
    "        im = Image.open(\"files/ch13/\"+file)\n",
    "        f1=np.asarray(im)\n",
    "        frames.append(f1)  \n",
    "imageio.mimsave('files/ch13/conn_DL_probs.gif',\\\n",
    "                frames,duration=500) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada070e0",
   "metadata": {},
   "source": [
    "If you open the file conn_DL_probs.gif, you'll see the animation as follows.\n",
    "<img src=\"https://gattonweb.uky.edu/faculty/lium/ml/conn_DL_probs.gif\" /> Note that your results will likely be different from mine due to the random nature of the game."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7dbb5c",
   "metadata": {},
   "source": [
    "## 13.4.4. Combine Board Positions and Decision Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "177de3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ch13util import DL_steps\n",
    "\n",
    "frames=DL_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd34819",
   "metadata": {},
   "source": [
    "If you open the gif file, you'll see the following animation:\n",
    "<img src=\"https://gattonweb.uky.edu/faculty/lium/ml/conn_DL_steps.gif\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9864b7",
   "metadata": {},
   "source": [
    "## 13.4.5 Create Subplots of Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c22ef4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_subplots=frames[2::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aee5f491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,28),dpi=200)\n",
    "for i in range(4):\n",
    "    plt.subplot(4,1,i+1)\n",
    "    plt.imshow(frames_subplots[i])\n",
    "    plt.axis('off')\n",
    "plt.subplots_adjust(bottom=0.001,right=0.999,top=0.999,\n",
    "        left=0.001, hspace=-0.1,wspace=-0.22)\n",
    "plt.savefig(\"files/ch13/subplots_conn.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ff08b4",
   "metadata": {},
   "source": [
    "# 13.6 Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "930d79fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer to question 13.2\n",
    "import time\n",
    "import random\n",
    "\n",
    "env=conn()\n",
    "state=env.reset()   \n",
    "env.render()\n",
    "print(f\"the current state is \\n{state.T[::-1]}\")    \n",
    "print('enter a number between 1 and 7')\n",
    "while True:   \n",
    "    action=random.choice(env.validinputs)\n",
    "    time.sleep(1)\n",
    "    print(f\"Player red has chosen action {action}\")    \n",
    "    state,reward,done,info=env.step(action)\n",
    "    print(f\"the current state is \\n{state.T[::-1]}\")\n",
    "    env.render()\n",
    "    if done:\n",
    "        if reward==1:\n",
    "            print(f\"Player red has won!\") \n",
    "        else:\n",
    "            print(f\"It's a tie!\") \n",
    "        break\n",
    "    action=int(input(\"Player red, what's your move?\"))\n",
    "    time.sleep(1)\n",
    "    print(f\"Player yellow has chosen action {action}\")    \n",
    "    state,reward,done,info=env.step(action)\n",
    "    env.render()\n",
    "    print(f\"the current state is \\n{state.T[::-1]}\")\n",
    "    if done:\n",
    "        if reward==-1:\n",
    "            print(f\"Player yellow has won!\") \n",
    "        else:\n",
    "            print(f\"It's a tie!\") \n",
    "        break    \n",
    "env.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d911596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer to question 13.3\n",
    "# stage 2\n",
    "p_wins_step1=history[1][1]\n",
    "for key, value in p_wins_step1.items():\n",
    "    print(f\"If red chooses {key},\\\n",
    " the probability of winning is {value:.4f}.\")\n",
    "# stage 3\n",
    "p_wins_step2=history[2][1]\n",
    "for key, value in p_wins_step2.items():\n",
    "    print(f\"If red chooses {key},\\\n",
    " the probability of winning is {value:.4f}.\")  \n",
    "# stage 4\n",
    "p_wins_step3=history[3][1]\n",
    "for key, value in p_wins_step3.items():\n",
    "    print(f\"If red chooses {key},\\\n",
    " the probability of winning is {value:.4f}.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afb55793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
